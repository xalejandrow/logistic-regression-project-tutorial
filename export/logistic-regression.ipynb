{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xalejandrow/logistic-regression-project-tutorial/blob/main/export/logistic-regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4befd825",
      "metadata": {
        "id": "4befd825"
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "Logistic Regression is a linear classification algorithm. Classification is a problem in which the task is to assign a category/class to a new instance learning the properties of each class from the existing labeled data, called training set. Examples of classification problems can be classifying emails as spam and non-spam, looking at height, weight, and other attributes to classify a person as fit or unfit, etc.\n",
        "\n",
        "\n",
        "In statistics, the logistic model (or logit model) is used to model the probability of a certain class or event existing such as pass/fail, win/lose, alive/dead or healthy/sick.\n",
        "\n",
        "**Why should we learn Logistic Regression?**\n",
        "\n",
        "- It is the first supervised learning algorithm that comes to the mind of data science practitioners to create a strong baseline model to check the uplift.\n",
        "\n",
        "- It is a fundamental, powerful, and easily implementable algorithm. It is also a very intuitive and interpretable model as the final outputs are coefficients depicting the relationship between response variable and features.\n",
        "\n",
        "**Is logistic regression a regressor or a classifier?**\n",
        "\n",
        "Logistic regression is usually used as a classifier because it predicts discrete classes.\n",
        "Having said that, it technically outputs a continuous value associated with each prediction, by producing a probability score along with its classification prediction.\n",
        "\n",
        "So we see that it is actually a regression algorithm that can solve classification problems.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c6744d4",
      "metadata": {
        "id": "7c6744d4"
      },
      "source": [
        "## What parameters can be tuned in logistic regression models?\n",
        "\n",
        "There are several hyperparameters that can be optimized in Logistic Regression. To see all the available ones and their possible values, click: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "\n",
        "However, here we will show you the main hyperparameters we may tune in logistic regression.\n",
        "\n",
        "**Solver** is the algorithm to use in the optimization problem. The choices are {‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, and the default value is ’lbfgs’.\n",
        "\n",
        "- *lbfgs* relatively performs well compared to other methods and it saves a lot of memory, however, sometimes it may have issues with convergence.\n",
        "\n",
        "- *sag* faster than other solvers for large datasets, when both the number of samples and the number of features are large.\n",
        "\n",
        "- *saga* the solver of choice for sparse multinomial logistic regression and it’s also suitable for very large datasets.\n",
        "\n",
        "- *newton-cg* computationally expensive because of the Hessian Matrix.\n",
        "\n",
        "- *liblinear* recommended when you have a high dimension dataset - solving large-scale classification problems. \n",
        "\n",
        ">Note: ‘sag’ and ‘saga’ fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing.\n",
        "\n",
        "**Penalty (or regularization)** intends to reduce model generalization error, and is meant to disincentivize and regulate overfitting. Technique discourages learning a more complex model, so as to avoid the risk of overfitting. The choices are: {‘l1’, ‘l2’, ‘elasticnet’, ‘none’}, and the default value is ’l2’. \n",
        "\n",
        ">Note: not all solvers support all regularization terms.\n",
        "\n",
        "**C (or regularization strength)** must be a positive float. Regularization strength works with the penalty to regulate overfitting. Smaller values specify stronger regularization and high value tells the model to give high weight to the training data.   \n",
        "\n",
        "\n",
        "Logistic regression offers other parameters like: \n",
        "\n",
        "-class_weight\n",
        "\n",
        "-dualbool (for sparse datasets when n_samples > n_features)\n",
        "\n",
        "-max_iter (may improve convergence with higher iterations), and others. However, these provide less impact."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a45109a1",
      "metadata": {
        "id": "a45109a1"
      },
      "source": [
        "## Using logistic regression in Titanic survival prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d42c0bce",
      "metadata": {
        "id": "d42c0bce"
      },
      "source": [
        "In Titanic dataset we have more than one feature, and with logistic regression we predict whether they survive or not. If the value the model predict would be 0.85, that would mean the person is 85% a survivor and 15% not a survivor.\n",
        "\n",
        "Let's imagine the titanic dataset only had one feature(Sex) and we would like to predict if the passenger survives or not, what we are trying to calculate is basically:\n",
        "\n",
        "$P(survive|sex=male)$\n",
        "\n",
        "$P(survive|sex=female)$\n",
        "\n",
        "When the probability is greater or equal than 0.5, the binary value is 1, and when the probability is less than 0.5, the binary value is 0. So, the person we just mentioned above would be classified as 1, which means he or she survived. \n",
        "\n",
        "### The logistic regression curve"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b620c91",
      "metadata": {
        "id": "2b620c91"
      },
      "source": [
        "![logistic_regression_curve](https://github.com/4GeeksAcademy/machine-learning-content/blob/master/assets/logistic_regression_curve.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3284fe19",
      "metadata": {
        "id": "3284fe19"
      },
      "source": [
        "The logistic function, also called the sigmoid function is an S-shaped curve that can take any real-valued number and map it into a value between 0 and 1, but never exactly at those limits.\n",
        "\n",
        "Logistic regression uses maximum-likelihood estimation, which calculates the likelihood of one person being a survivor on Titanic, and then another one, and then another one. After all calculations are done, the model multiplies all those likelihoods and fits the S-shaped line to the data. Keeps calculating, until it finds the best S-shaped line. \n",
        "\n",
        "### The logistic regression equation\n",
        "\n",
        "Input values (x) are combined linearly using weights or coefficient values (referred to as the Greek capital letter Beta) to predict an output value (y). A key difference from linear regression is that the output value being modeled is a binary values (0 or 1) rather than a numeric value.\n",
        "\n",
        "Below is an example logistic regression equation:\n",
        "\n",
        "$y = e^(b0 + b1*x) / (1 + e^(b0 + b1*x))$\n",
        "\n",
        "Where y is the predicted output, b0 is the bias or intercept term and b1 is the coefficient for the single input value (x). Each column in your input data has an associated b coefficient (a constant real value) that must be learned from your training data. This is done using maximum-likelihood estimation. The intuition for maximum-likelihood for logistic regression is that a search procedure seeks values for the coefficients (Beta values) that minimize the error in the probabilities predicted by the model to those in the data.\n",
        "\n",
        "The actual representation of the model that you would store in memory or in a file are the coefficients in the equation (the beta value or b’s).\n",
        "\n",
        "To get the probabilities with Python you can use:\n",
        "\n",
        "```py\n",
        "\n",
        "y_pred = model.predict_proba(X_test)\n",
        "roc_auc_score(y_test, y_pred)\n",
        "\n",
        "```\n",
        "\n",
        "This will give you an array of 'probability to be in each class' given to each observation, but you can also get the probability to be in the class '1':\n",
        "\n",
        "```py\n",
        "\n",
        "# Score\n",
        "\n",
        "y_pred = model.predict_proba(X_test)[:, 1]\n",
        "roc_auc_score(y_test, y_pred)\n",
        "\n",
        "```\n",
        "\n",
        "### Titanic Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72bc9351",
      "metadata": {
        "id": "72bc9351"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce8ef169",
      "metadata": {
        "id": "ce8ef169"
      },
      "source": [
        "**Loading the final dataframe**\n",
        "\n",
        "In order to start modeling, we will focus on our train data and forget temporarily about the dataset where we need to make predictions.\n",
        "\n",
        "Let's start by loading our clean titanic train data and name it final_df."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cc5a262",
      "metadata": {
        "id": "8cc5a262"
      },
      "outputs": [],
      "source": [
        "# loading clean train dataset\n",
        "\n",
        "final_df = pd.read_csv('https://raw.githubusercontent.com/4GeeksAcademy/machine-learning-content/master/assets/clean_titanic_train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61fc24cd",
      "metadata": {
        "id": "61fc24cd",
        "outputId": "8235422e-1217-46f2-cc28-a43d18ba29c4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "      <th>Female</th>\n",
              "      <th>Male</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>fam_mbrs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.271174</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.027567</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.472229</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.271039</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.321438</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.030133</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.201901</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.030608</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.346569</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.032161</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.673285</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.197196</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.019854</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.080133</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.334004</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.042332</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.170646</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.114338</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Embarked_C  Embarked_Q  Embarked_S  Female  Male  Survived  \\\n",
              "0           0         0.0         0.0         1.0     0.0   1.0       0.0   \n",
              "1           1         1.0         0.0         0.0     1.0   0.0       1.0   \n",
              "2           2         0.0         0.0         1.0     1.0   0.0       1.0   \n",
              "3           3         0.0         0.0         1.0     1.0   0.0       1.0   \n",
              "4           4         0.0         0.0         1.0     0.0   1.0       0.0   \n",
              "5           5         0.0         1.0         0.0     0.0   1.0       0.0   \n",
              "6           6         0.0         0.0         1.0     0.0   1.0       0.0   \n",
              "7           7         0.0         0.0         1.0     0.0   1.0       0.0   \n",
              "8           8         0.0         0.0         1.0     1.0   0.0       1.0   \n",
              "9           9         1.0         0.0         0.0     1.0   0.0       1.0   \n",
              "\n",
              "   Pclass       Age  SibSp  Parch      Fare  fam_mbrs  \n",
              "0     3.0  0.271174    1.0    0.0  0.027567       1.0  \n",
              "1     1.0  0.472229    1.0    0.0  0.271039       1.0  \n",
              "2     3.0  0.321438    0.0    0.0  0.030133       0.0  \n",
              "3     1.0  0.434531    1.0    0.0  0.201901       1.0  \n",
              "4     3.0  0.434531    0.0    0.0  0.030608       0.0  \n",
              "5     3.0  0.346569    0.0    0.0  0.032161       0.0  \n",
              "6     1.0  0.673285    0.0    0.0  0.197196       0.0  \n",
              "7     3.0  0.019854    3.0    1.0  0.080133       4.0  \n",
              "8     3.0  0.334004    0.0    2.0  0.042332       2.0  \n",
              "9     2.0  0.170646    1.0    0.0  0.114338       1.0  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's take a look at our first 10 rows to verify all data is numerical\n",
        "\n",
        "final_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea1adc7d",
      "metadata": {
        "id": "ea1adc7d"
      },
      "source": [
        "**Separate features and target as X and y**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6a524ab",
      "metadata": {
        "id": "f6a524ab"
      },
      "outputs": [],
      "source": [
        "X = final_df.drop(['Survived','Unnamed: 0'], axis=1)\n",
        "y = final_df['Survived']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c767616",
      "metadata": {
        "id": "7c767616"
      },
      "source": [
        "**Split dataframe in training set and testing set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae54636d",
      "metadata": {
        "id": "ae54636d"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80afe320",
      "metadata": {
        "id": "80afe320"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Instantiate Logistic Regression\n",
        "\n",
        "model = LogisticRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "275f668c",
      "metadata": {
        "id": "275f668c",
        "outputId": "654e4255-1ba2-4d2d-9ac2-1e4279693817"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fit the data\n",
        "\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d331b6c",
      "metadata": {
        "id": "2d331b6c",
        "outputId": "e962b6df-c1d6-465f-cec7-d455ef507274"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
              "       1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       1., 1., 1., 0., 1., 0., 1., 1.])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7153045",
      "metadata": {
        "id": "e7153045",
        "outputId": "b84d1004-674c-44ec-b6cf-5fa92e454ba7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8146067415730337"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the accuracy score\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2072d9c4",
      "metadata": {
        "id": "2072d9c4",
        "outputId": "b2e7e34c-7223-43bb-8775-d251bd7366b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[87, 16],\n",
              "       [17, 58]])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "titanic_cm = confusion_matrix(y_pred, y_test)\n",
        "titanic_cm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff2b1602",
      "metadata": {
        "id": "ff2b1602"
      },
      "source": [
        "If you want you can put your confusion matrix a more beautiful graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b070aed",
      "metadata": {
        "id": "0b070aed",
        "outputId": "bb9f944a-bb6c-409f-f9bd-1f6a8aace271"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# convert the ndarray to a pandas dataframe\n",
        "cm_df = pd.DataFrame(titanic_cm)\n",
        "# set the size of the figure\n",
        "plt.figure(figsize = (5,5))\n",
        "sns.heatmap(cm_df, \n",
        "           annot=True, annot_kws={\"size\": 25},\n",
        "           fmt=\"d\",         # decimals format\n",
        "           xticklabels=False, \n",
        "           yticklabels=False,\n",
        "           cmap=\"viridis\", \n",
        "           cbar=False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28fd0338",
      "metadata": {
        "id": "28fd0338"
      },
      "source": [
        "Observations: 16 + 17 = 33 wrong prediction. Can we can do better?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45688802",
      "metadata": {
        "id": "45688802"
      },
      "source": [
        "Let's use GridSearch to see what would be the best hyperparameters for our Logistic Regression model. \n",
        "\n",
        "The code below demonstrates grid searching the key hyperparameters for LogisticRegression on a binary classification dataset, in this case our Titanic dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07004e36",
      "metadata": {
        "id": "07004e36",
        "outputId": "778ca414-3ceb-4a06-f4e2-607a0d489646"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best: 0.798102 using {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.793216 (0.032933) with: {'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.793216 (0.032933) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.792833 (0.031946) with: {'C': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.793212 (0.032824) with: {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.793212 (0.032824) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.793969 (0.031699) with: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.796582 (0.034081) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.796582 (0.034081) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.796229 (0.036167) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.798102 (0.037820) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.798102 (0.037820) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.797706 (0.040030) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.783801 (0.034749) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.783801 (0.034749) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.783048 (0.033317) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# define models and parameters\n",
        "\n",
        "model = LogisticRegression()\n",
        "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "penalty = ['l2']\n",
        "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
        "\n",
        "# define grid search\n",
        "\n",
        "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "grid_result = grid_search.fit(X, y)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc072cbe",
      "metadata": {
        "id": "cc072cbe"
      },
      "source": [
        "Solver newton-cg supports only 'l2' or 'none' penalties, that is why we only included 'l2'.\n",
        "\n",
        "\n",
        "Observations: We actually got a better score first. Let's confirm these by getting the confusion matrix again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12be01d9",
      "metadata": {
        "id": "12be01d9"
      },
      "outputs": [],
      "source": [
        "# Hypertune parameters\n",
        "\n",
        "optimized_model = LogisticRegression(C= 0.1, penalty='l2', solver= 'newton-cg')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c54d280",
      "metadata": {
        "id": "0c54d280",
        "outputId": "67edb1c6-9202-406c-d124-a641766c47dd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1, solver=&#x27;newton-cg&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1, solver=&#x27;newton-cg&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(C=0.1, solver='newton-cg')"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fit the data\n",
        "\n",
        "optimized_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e95e0c7",
      "metadata": {
        "id": "4e95e0c7",
        "outputId": "a9a443f4-1eea-4e44-de34-ec309adf84b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
              "       1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       1., 1., 1., 0., 1., 0., 1., 1.])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make predictions\n",
        "y_pred = optimized_model.predict(X_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99de24a3",
      "metadata": {
        "id": "99de24a3",
        "outputId": "51ca52c6-f0d1-4507-afb2-600d7e19dddd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8089887640449438"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the accuracy score\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "accuracy_score(y_pred, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9391d4f8",
      "metadata": {
        "id": "9391d4f8",
        "outputId": "595edc7b-9032-4dc0-b3cc-470c5d03d9d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[85, 15],\n",
              "       [19, 59]])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "confusion_matrix(y_pred, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d2ccf0d",
      "metadata": {
        "id": "9d2ccf0d"
      },
      "source": [
        "Observations: In effect, we now have 34 (15 + 19) wrong predictions. We had 33 with our first baseline model.\n",
        "\n",
        "In the last data preprocessing module we learned some techniques of feature selection if needed. However, the final clean dataset was saved before any feature selection implementation. So let's a feature selection technique here and see if it makes our model improve.\n",
        "\n",
        "**Recursive feature elimination**\n",
        "\n",
        "Given an external estimator that assigns weights to features, recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a coef_ attribute or through a feature_importances_ attribute. Then, the least important features are pruned from current set of features.That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8297226",
      "metadata": {
        "id": "a8297226",
        "outputId": "2a90a71e-88e5-4c82-dc7c-0717c7251dde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected features: ['Embarked_C', 'Embarked_Q', 'Embarked_S', 'Female', 'Male', 'Pclass', 'Age', 'SibSp', 'fam_mbrs']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# create the RFE model and select 9 attributes\n",
        "rfe = RFE(model, n_features_to_select=9)\n",
        "rfe = rfe.fit(X, y)\n",
        "\n",
        "# summarize the selection of the attributes\n",
        "print('Selected features: %s' % list(X.columns[rfe.support_]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc4ca008",
      "metadata": {
        "id": "fc4ca008"
      },
      "source": [
        "These are the 9 attributes suggested. But is 9 the optimal number of Titanic features to enter my model?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80b3b955",
      "metadata": {
        "id": "80b3b955"
      },
      "source": [
        "**Feature ranking with recursive feature elimination and cross-validation**\n",
        "\n",
        "RFECV performs RFE in a cross-validation loop to find the optimal number or the best number of features. Hereafter a recursive feature elimination applied on logistic regression with automatic tuning of the number of features selected with cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "275b28de",
      "metadata": {
        "id": "275b28de",
        "outputId": "39edb86c-f841-4b94-b5f7-835544cf35a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimal number of features: 8\n",
            "Selected features: ['Embarked_C', 'Embarked_Q', 'Embarked_S', 'Female', 'Male', 'Pclass', 'Age', 'SibSp']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages/sklearn/utils/deprecation.py:103: FutureWarning: The `grid_scores_` attribute is deprecated in version 1.0 in favor of `cv_results_` and will be removed in version 1.2.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.feature_selection import RFECV\n",
        "\n",
        "# Create the RFE object and compute a cross-validated score.\n",
        "# The \"accuracy\" scoring is proportional to the number of correct classifications\n",
        "\n",
        "rfecv = RFECV(estimator=LogisticRegression(), step=1, cv=10, scoring='accuracy')\n",
        "rfecv.fit(X, y)\n",
        "\n",
        "print(\"Optimal number of features: %d\" % rfecv.n_features_)\n",
        "print('Selected features: %s' % list(X.columns[rfecv.support_]))\n",
        "\n",
        "# Plot number of features VS. cross-validation scores\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
        "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23d14322",
      "metadata": {
        "id": "23d14322"
      },
      "source": [
        "Observations: We see that the optimal number of features suggested is actually 8. The total number of family members was not considered as important."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7057a053",
      "metadata": {
        "id": "7057a053"
      },
      "source": [
        "**Model evaluation based on K-fold cross-validation using cross_val_score() function**\n",
        "\n",
        "- This time we are going to use a new features dataframe (new_X) with only the selected features.\n",
        "\n",
        "- This time the split method will be K-fold cross-validation with 10 folds.\n",
        "\n",
        "- The model will still be Logistic regression but we will use the best hyperparameters we got in the gridsearch.\n",
        "\n",
        "- We know that accuracy is not always the best or always poor measure for assesing. There are many metrics like Recall, Precision, F1 Score and much more. We will propose 3 different evaluation metrics. The metrics proposed will be 'accuracy', 'neg_log_loss', and 'roc_auc'.\n",
        "\n",
        "- Finally, the cross_val_score() function will be used to perform the evaluation, taking the dataset and cross-validation configuration and returning a list of scores calculated for each fold.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bf8b662",
      "metadata": {
        "id": "0bf8b662",
        "outputId": "f2668738-3ff3-4061-8201-ac0754d3db01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-fold cross-validation results:\n",
            "LogisticRegression average accuracy is 0.798\n",
            "LogisticRegression average log_loss is 0.459\n",
            "LogisticRegression average auc is 0.847\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score \n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc, log_loss\n",
        "\n",
        "Selected_features = ['Embarked_C', 'Embarked_Q', 'Embarked_S', 'Female', 'Male', 'Pclass', 'Age', 'SibSp']\n",
        "\n",
        "# create new X (selected features) \n",
        "new_X = final_df[Selected_features]\n",
        "\n",
        "# 10-fold cross-validation logistic regression, using the best hyperparameters gridsearch got for us.\n",
        "\n",
        "logreg = LogisticRegression(C= 0.1, penalty='l2', solver= 'newton-cg')\n",
        "\n",
        "# Use cross_val_score function\n",
        "# We are passing the entirety of X and y, not X_train or y_train anymore.\n",
        "# cv=10 for 10 folds\n",
        "# scoring = {'accuracy', 'neg_log_loss', 'roc_auc'} for evaluation metric\n",
        "\n",
        "scores_accuracy = cross_val_score(logreg, new_X, y, cv=10, scoring='accuracy')\n",
        "scores_log_loss = cross_val_score(logreg, new_X, y, cv=10, scoring='neg_log_loss')\n",
        "scores_auc = cross_val_score(logreg, new_X, y, cv=10, scoring='roc_auc')\n",
        "\n",
        "print('K-fold cross-validation results:')\n",
        "print(logreg.__class__.__name__+\" average accuracy is %2.3f\" % scores_accuracy.mean())\n",
        "print(logreg.__class__.__name__+\" average log_loss is %2.3f\" % -scores_log_loss.mean())\n",
        "print(logreg.__class__.__name__+\" average auc is %2.3f\" % scores_auc.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "537ce0df",
      "metadata": {
        "id": "537ce0df"
      },
      "source": [
        "Notice that by using the 'roc_auc' metric we would have got a better score than accuracy. If we would want to repeat our modeling process using this evaluation metric, consider using the predict_proba(X_test) to predict the probabilities also graph auc_roc curves, because if you use model.predict(X_test), the method won’t have all the necessary information to build all the points in the curve.\n",
        "\n",
        "Let's finish our class predictions!\n",
        "\n",
        "We need to fit the whole training data to the estimator once we are satisfied with the results of cross_val_score, before we can use it to predict on Titanic test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a6a6180",
      "metadata": {
        "id": "3a6a6180",
        "outputId": "9023165c-67cc-4e7c-aace-85f93b4f58eb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1, solver=&#x27;newton-cg&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1, solver=&#x27;newton-cg&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(C=0.1, solver='newton-cg')"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's fit our entire titanic train data with this model\n",
        "\n",
        "logreg.fit(new_X,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b0e4976",
      "metadata": {
        "id": "1b0e4976"
      },
      "source": [
        "In the following code, let's see how to generate our predictions, and save them in a predictions file with the right Id."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "466442e7",
      "metadata": {
        "id": "466442e7"
      },
      "outputs": [],
      "source": [
        "#Load initial test set (the one that was not cleaned yet and where we need to make predictions)\n",
        "\n",
        "initial_test_df = pd.read_csv('https://raw.githubusercontent.com/4GeeksAcademy/machine-learning-content/master/assets/titanic_test.csv')\n",
        "\n",
        "#Load cleaned test set\n",
        "\n",
        "final_test = pd.read_csv('https://raw.githubusercontent.com/4GeeksAcademy/machine-learning-content/master/assets/clean_titanic_test.csv')\n",
        "\n",
        "#Adding the column survived to clean test set in order to make predictions\n",
        "\n",
        "final_test['Survived'] = logreg.predict(final_test[Selected_features])\n",
        "\n",
        "#Putting the 'PassengerId' column back to test set\n",
        "\n",
        "final_test['PassengerId'] = initial_test_df['PassengerId']\n",
        "\n",
        "#Creating a final predictions dataframe\n",
        "\n",
        "submission = final_test[['PassengerId','Survived']]\n",
        "\n",
        "# Convert final dataframe in a csv file\n",
        "# Normally this is the required csv file in Kaggle competitions\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faba28d6",
      "metadata": {
        "id": "faba28d6"
      },
      "source": [
        "Take a look at our predictions in the last rows of the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5141790e",
      "metadata": {
        "id": "5141790e",
        "outputId": "befbe1e1-d9a4-4f84-c48d-9766e9fd8382"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>1305</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>1306</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>1307</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>1308</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>1309</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived\n",
              "413         1305       0.0\n",
              "414         1306       1.0\n",
              "415         1307       0.0\n",
              "416         1308       0.0\n",
              "417         1309       0.0"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "submission.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e41526e1",
      "metadata": {
        "id": "e41526e1"
      },
      "source": [
        "## Import considerations before modeling with Logistic Regression \n",
        "\n",
        "Ultimately in predictive modeling machine learning projects we are focused on making accurate predictions rather than interpreting the results. As such, we can break some assumptions as long as the model is robust and performs well.\n",
        "\n",
        "- Binary Output Variable: This might be obvious as we have already mentioned it, but logistic regression is intended for binary (two-class) classification problems. It will predict the probability of an instance belonging to the default class, which can be snapped into a 0 or 1 classification.\n",
        "\n",
        "- Remove Noise: Logistic regression assumes no error in the output variable (y), consider removing outliers and possibly misclassified instances from your training data.\n",
        "\n",
        "- Gaussian Distribution: Logistic regression is a linear algorithm (with a non-linear transform on output). It does assume a linear relationship between the input variables with the output. Data transforms of your input variables that better expose this linear relationship can result in a more accurate model. For example, you can use log, root, Box-Cox and other univariate transforms to better expose this relationship.\n",
        "\n",
        "- Remove Correlated Inputs: Like linear regression, the model can overfit if you have multiple highly-correlated inputs. Consider calculating the pairwise correlations between all inputs and removing highly correlated inputs.\n",
        "\n",
        "- Fail to Converge: It is possible for the expected likelihood estimation process that learns the coefficients to fail to converge. This can happen if there are many highly correlated inputs in your data or the data is very sparse (e.g. lots of zeros in your input data)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9de9a255",
      "metadata": {
        "id": "9de9a255"
      },
      "source": [
        "Considering this, are there any changes you would do in your data preprocessing phase?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e5e27c6",
      "metadata": {
        "id": "1e5e27c6"
      },
      "source": [
        "Source: \n",
        "\n",
        "https://towardsdatascience.com/a-handbook-for-logistic-regression-bb2d0dc6d8a8\n",
        "\n",
        "https://www.displayr.com/how-to-interpret-logistic-regression-coefficients/\n",
        "\n",
        "https://towardsdatascience.com/a-handbook-for-logistic-regression-bb2d0dc6d8a8\n",
        "\n",
        "https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/#:~:text=Logistic%20regression%20does%20not%20really,with%20different%20solvers%20(solver).&text=Regularization%20(penalty)%20can%20sometimes%20be%20helpful.\n",
        "\n",
        "https://machinelearningmastery.com/logistic-regression-for-machine-learning/\n",
        "\n",
        "https://www.kaggle.com/code/mnassrib/titanic-logistic-regression-with-python/notebook\n",
        "\n",
        "https://www.kaggle.com/code/rmiperrier/tps-mar-lgbm-predict-proba-vs-predict?scriptVersionId=55643096\n",
        "\n",
        "https://medium.com/codex/do-i-need-to-tune-logistic-regression-hyperparameters-1cb2b81fca69\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.13 64-bit ('3.8.13')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
      }
    },
    "colab": {
      "name": "logistic-regression.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}